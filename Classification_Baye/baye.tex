%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% a0poster Portrait Poster
% LaTeX Template
% Version 1.0 (22/06/13)
%
% The a0poster class was created by:
% Gerlinde Kettl and Matthias Weiser (tex@kettl.de)
% 
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0,portrait]{a0poster}

\usepackage{multicol} % This is so we can have multiple columns of text side-by-side
\columnsep=100pt % This is the amount of white space between the columns in the poster
\columnseprule=3pt % This is the thickness of the black line between the columns in the poster

\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors

\usepackage{times} % Use the times font
%\usepackage{palatino} % Uncomment to use the Palatino font

\usepackage{graphicx} % Required for including images
\graphicspath{{figures/}} % Location of the graphics files
\usepackage{booktabs} % Top and bottom rules for table
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
\usepackage{amsfonts, amsmath, amsthm, amssymb} % For math fonts, symbols and environments
\usepackage{wrapfig} % Allows wrapping text around tables and figures
\usepackage{hyperref}

\begin{document}

%----------------------------------------------------------------------------------------
%	POSTER HEADER 
%----------------------------------------------------------------------------------------

% The header is divided into two boxes:
% The first is 75% wide and houses the title, subtitle, names, university/organization and contact information
% The second is 25% wide and houses a logo for your university/organization or a photo of you
% The widths of these boxes can be easily edited to accommodate your content as you see fit

\begin{minipage}[b]{0.75\linewidth}
\veryHuge \color{NavyBlue} \textbf{Classification naive Bayésienne} \color{Black}\\ % Title
\Huge\textit{fiche d'aide}\\[2cm] % Subtitle
\huge Arts et Metiers\\[0.4cm] % University/organization
\\
\end{minipage}
%
\begin{minipage}[b]{0.25\linewidth}
\includegraphics[width=20cm]{logo.png}\\
\end{minipage}

\vspace{1cm} % A bit of extra whitespace between the header and poster content

%----------------------------------------------------------------------------------------

% \begin{multicols}{1} % This is how many columns your poster will be broken into, a portrait poster is generally split into 2 columns

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------



%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\color{SaddleBrown} % SaddleBrown color for the introduction

\section*{A quoi sert l'algorithme ?}

La classification naïve bayésienne est utilisée dans divers domaines pour la classification et la prédiction. Elle est particulièrement efficace pour la classification de textes (comme le filtrage des spams), la reconnaissance de patterns dans les données, et dans des applications de machine learning où la simplicité et la rapidité sont cruciales.

%----------------------------------------------------------------------------------------
%	OBJECTIVES
%----------------------------------------------------------------------------------------

\color{DarkSlateGray} % DarkSlateGray color for the rest of the content

\section*{Comment fonctionne la classification naive Bayésienne ?}

La méthode repose sur le théorème de Bayes et suppose que les caractéristiques d'une donnée sont indépendantes entre elles. Pour classer une donnée, le modèle calcule la probabilité de chaque classe possible et choisit la classe ayant la probabilité la plus élevée. Cela se fait en analysant les caractéristiques de la donnée et en se basant sur des données d'entraînement préalablement fournies

%----------------------------------------------------------------------------------------
%	MATERIALS AND METHODS
%----------------------------------------------------------------------------------------

\section*{Avantages et Inconvenients}

%------------------------------------------------

\subsection*{Avantages}

\begin{enumerate}
    \item Simplicité et Rapidité : Facile à implémenter et rapide dans les calculs.
    \item Efficace avec de Grandes Bases de Données : Performe bien même avec de grandes quantités de données.
    \item Bon avec les Données Indépendantes : Excellente performance lorsque les caractéristiques des données sont indépendantes
\end{enumerate}

\subsection*{Inconvenients}

\begin{enumerate}
    \item Hypothèse d'Indépendance : Peut être irréaliste dans certains cas, ce qui affecte la performance.
    \item Sensibilité à la Donnée d'Entraînement : La qualité de la classification dépend fortement de la qualité des données d'entraînement.
\end{enumerate}

%----------------------------------------------------------------------------------------
%	RESULTS 
%----------------------------------------------------------------------------------------

\section*{Exemple}

Considérons le filtrage des e-mails en tant que "spam" ou "non-spam". La classification naïve bayésienne analyse les mots dans les e-mails et, en se basant sur la fréquence des mots dans les catégories de spam et de non-spam apprises lors de l'entraînement, détermine la probabilité qu'un e-mail donné soit du spam.

%\begin{center}\vspace{1cm}
%    \includegraphics[width=0.4\linewidth]{}
%\end{center}


%----------------------------------------------------------------------------------------
%	CONCLUSIONS
%----------------------------------------------------------------------------------------

\color{DarkSlateGray} % Set the color back to DarkSlateGray for the rest of the content
\section{Pour aller plus loin}
\textbf{Lissage de Laplace} : Pour éviter le problème des probabilités nulles (lorsqu'un attribut n'apparaît pas dans le jeu de données d'entraînement), le lissage de Laplace est souvent utilisé. Cette technique ajuste les probabilités pour prendre en compte les caractéristiques non observées.\newline
\textbf{Modèles de Probabilité} : Selon le type de données, différents modèles de probabilité peuvent être appliqués. Par exemple, le modèle de Bernoulli traite les attributs comme des variables binaires, tandis que le modèle multinomial est adapté aux caractéristiques discrètes, comme les fréquences de mots dans le traitement du texte.


%----------------------------------------------------------------------------------------
%	ACKNOWLEDGEMENTS
%----------------------------------------------------------------------------------------

\section*{Pour aller plus loin}

\begin{enumerate}
    \item \href{https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html}{Scikit-learn}.
    \item \href{https://en.wikipedia.org/wiki/Linear_regression.}{Wikipedia}
\end{enumerate}

%----------------------------------------------------------------------------------------

%\end{multicols}
\end{document}